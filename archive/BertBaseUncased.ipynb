{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "fckVKI_Fiw1D"
   },
   "source": [
    "# Transfer Learning Using BERT\n",
    "Adapted from [this tutorial](https://towardsdatascience.com/text-classification-with-bert-in-pytorch-887965e5820f) using [bert-base-cased](https://huggingface.co/bert-base-cased). Rather than predicting the masked word in a sentence, the new model predicts the masked label. This was implemented in the hopes that transfer learning would significantly improve modeling outcomes, but performance was on-par with the much more efficient fastText model. Included here only for reference."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "id": "fk3oDkyvit8y",
    "outputId": "2ab9d03f-0887-402e-da56-82da7206b12a"
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Looking in indexes: https://pypi.org/simple, https://us-python.pkg.dev/colab-wheels/public/simple/\n",
      "Collecting transformers\n",
      "  Downloading transformers-4.21.0-py3-none-any.whl (4.7 MB)\n",
      "\u001b[K     |████████████████████████████████| 4.7 MB 5.0 MB/s \n",
      "\u001b[?25hRequirement already satisfied: numpy>=1.17 in /usr/local/lib/python3.7/dist-packages (from transformers) (1.21.6)\n",
      "Requirement already satisfied: tqdm>=4.27 in /usr/local/lib/python3.7/dist-packages (from transformers) (4.64.0)\n",
      "Requirement already satisfied: regex!=2019.12.17 in /usr/local/lib/python3.7/dist-packages (from transformers) (2022.6.2)\n",
      "Requirement already satisfied: requests in /usr/local/lib/python3.7/dist-packages (from transformers) (2.23.0)\n",
      "Collecting huggingface-hub<1.0,>=0.1.0\n",
      "  Downloading huggingface_hub-0.8.1-py3-none-any.whl (101 kB)\n",
      "\u001b[K     |████████████████████████████████| 101 kB 10.4 MB/s \n",
      "\u001b[?25hRequirement already satisfied: importlib-metadata in /usr/local/lib/python3.7/dist-packages (from transformers) (4.12.0)\n",
      "Collecting pyyaml>=5.1\n",
      "  Downloading PyYAML-6.0-cp37-cp37m-manylinux_2_5_x86_64.manylinux1_x86_64.manylinux_2_12_x86_64.manylinux2010_x86_64.whl (596 kB)\n",
      "\u001b[K     |████████████████████████████████| 596 kB 62.7 MB/s \n",
      "\u001b[?25hRequirement already satisfied: packaging>=20.0 in /usr/local/lib/python3.7/dist-packages (from transformers) (21.3)\n",
      "Collecting tokenizers!=0.11.3,<0.13,>=0.11.1\n",
      "  Downloading tokenizers-0.12.1-cp37-cp37m-manylinux_2_12_x86_64.manylinux2010_x86_64.whl (6.6 MB)\n",
      "\u001b[K     |████████████████████████████████| 6.6 MB 50.5 MB/s \n",
      "\u001b[?25hRequirement already satisfied: filelock in /usr/local/lib/python3.7/dist-packages (from transformers) (3.7.1)\n",
      "Requirement already satisfied: typing-extensions>=3.7.4.3 in /usr/local/lib/python3.7/dist-packages (from huggingface-hub<1.0,>=0.1.0->transformers) (4.1.1)\n",
      "Requirement already satisfied: pyparsing!=3.0.5,>=2.0.2 in /usr/local/lib/python3.7/dist-packages (from packaging>=20.0->transformers) (3.0.9)\n",
      "Requirement already satisfied: zipp>=0.5 in /usr/local/lib/python3.7/dist-packages (from importlib-metadata->transformers) (3.8.1)\n",
      "Requirement already satisfied: chardet<4,>=3.0.2 in /usr/local/lib/python3.7/dist-packages (from requests->transformers) (3.0.4)\n",
      "Requirement already satisfied: urllib3!=1.25.0,!=1.25.1,<1.26,>=1.21.1 in /usr/local/lib/python3.7/dist-packages (from requests->transformers) (1.24.3)\n",
      "Requirement already satisfied: certifi>=2017.4.17 in /usr/local/lib/python3.7/dist-packages (from requests->transformers) (2022.6.15)\n",
      "Requirement already satisfied: idna<3,>=2.5 in /usr/local/lib/python3.7/dist-packages (from requests->transformers) (2.10)\n",
      "Installing collected packages: pyyaml, tokenizers, huggingface-hub, transformers\n",
      "  Attempting uninstall: pyyaml\n",
      "    Found existing installation: PyYAML 3.13\n",
      "    Uninstalling PyYAML-3.13:\n",
      "      Successfully uninstalled PyYAML-3.13\n",
      "Successfully installed huggingface-hub-0.8.1 pyyaml-6.0 tokenizers-0.12.1 transformers-4.21.0\n"
     ]
    }
   ],
   "source": [
    "#install hugging face transformers - if needed\n",
    "!pip install transformers"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {
    "id": "4L0d5SEti6gH"
   },
   "outputs": [],
   "source": [
    "#imports\n",
    "import pandas as pd\n",
    "import numpy as np\n",
    "from torch import nn, cuda, no_grad, save, backends, manual_seed\n",
    "from torch import device as dvc\n",
    "from torch.optim import Adam\n",
    "from torch.utils.data import DataLoader, Dataset\n",
    "from transformers import BertTokenizer, BertModel\n",
    "from tqdm import tqdm\n",
    "import gc\n",
    "from google.colab import files"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {
    "id": "A-_kCs93wPrD"
   },
   "outputs": [],
   "source": [
    "#for reproducible results: https://vandurajan91.medium.com/random-seeds-and-reproducible-results-in-pytorch-211620301eba\n",
    "#DataLoaders may still introduce randomness: https://pytorch.org/docs/stable/notes/randomness.html\n",
    "random_seed = 42\n",
    "manual_seed(random_seed)\n",
    "cuda.manual_seed(random_seed)\n",
    "backends.cudnn.deterministic = True\n",
    "backends.cudnn.benchmark = False\n",
    "np.random.seed(random_seed)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {
    "id": "TR4o7li3qty_"
   },
   "outputs": [],
   "source": [
    "#load in data\n",
    "train = pd.read_csv(\"spacy_train.csv\", dtype={\"grade_reduced\": str})\n",
    "val = pd.read_csv(\"spacy_val.csv\", dtype={\"grade_reduced\": str})\n",
    "test = pd.read_csv(\"spacy_test.csv\", dtype={\"grade_reduced\": str})"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "FR4aqGmjdFnU"
   },
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {
    "id": "jyaJcfVXaRTu"
   },
   "outputs": [],
   "source": [
    "class ClassificationDataset(Dataset):\n",
    "    \"\"\"\n",
    "    Creates a PyTorch compatible Dataset from the given DataFrame to be used with the BertClassifier model\n",
    "\n",
    "    Variables:\n",
    "    df: DataFrame with the x and y columns\n",
    "    x_col: Str: The text feature to be modeled on\n",
    "    y_col: Str: The target classification column\n",
    "    bert_type: Str: Name of the pre-trained Bert model to use\n",
    "    labels: Dict: Dictionary converting the labels in the y_col of the DataFrame to numeric\n",
    "    \"\"\"\n",
    "    def __init__(self, df, x_col, y_col, tokenizer, labels):\n",
    "\n",
    "        self.labels = [labels[label] for label in df[y_col]]\n",
    "        self.texts = [tokenizer(x, \n",
    "                                padding = 'max_length', \n",
    "                                max_length = 512, \n",
    "                                truncation = True,\n",
    "                                return_tensors=\"pt\")\n",
    "                       for x in df[x_col]]\n",
    "\n",
    "    #number of \"rows\"              \n",
    "    def __len__(self):\n",
    "        return len(self.texts)\n",
    "\n",
    "    #return one x, y pair (to the DataLoader)\n",
    "    def __getitem__(self, idx):\n",
    "        return self.texts[idx], self.labels[idx]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {
    "id": "9_7K8BeFooxX"
   },
   "outputs": [],
   "source": [
    "class BertClassifier(nn.Module):\n",
    "    \"\"\"\n",
    "    Neural Network Classifier \n",
    "    bert_type: Str: Name of the pre-trained Bert model to use\n",
    "    num_labels: Int: Number of target classes\n",
    "    \"\"\"\n",
    "\n",
    "    def __init__(self, bert_type, num_labels, dropout=1):\n",
    "\n",
    "        #just a pytorch thing, keep it!\n",
    "        super(BertClassifier, self).__init__()\n",
    "\n",
    "        self.bert = BertModel.from_pretrained(bert_type)\n",
    "        self.dropout = nn.Dropout(dropout) # default keeps all values, likely needs to be adjusted to avoid overfitting\n",
    "        self.linear = nn.Linear(768, num_labels)\n",
    "        self.relu = nn.ReLU()\n",
    "        self.losses = {'train' : [],\n",
    "                       'val' : [],\n",
    "                       'test' : []}\n",
    "        self.accuracy = {'train' : [],\n",
    "                         'val' : [],\n",
    "                         'test' : []}\n",
    "\n",
    "    def forward(self, input_id, mask): # mask tells us which tokens are not [PAD]\n",
    "        _, pooled_output = self.bert(input_ids=input_id, attention_mask=mask, return_dict=False)\n",
    "        dropout_output = self.dropout(pooled_output)\n",
    "        linear_output = self.linear(dropout_output)\n",
    "        final_layer = self.relu(linear_output)\n",
    "        return final_layer\n",
    "\n",
    "    def update_loss(self, loss_type, value):\n",
    "        self.losses[loss_type].append(value)\n",
    "\n",
    "    def update_acc(self, acc_type, value):\n",
    "        self.accuracy[acc_type].append(value)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {
    "id": "hEUxXcZpzH5J"
   },
   "outputs": [],
   "source": [
    "def evaluate(model, data, device, criterion=None, batch_size=2, result_type=None):\n",
    "    \"\"\"\n",
    "    Takes in a neural net and set of data and returns the performance of the model on the data\n",
    "    \"\"\"\n",
    "    dataloader = DataLoader(data, batch_size=batch_size)\n",
    "\n",
    "    total_acc = 0\n",
    "    total_loss = 0\n",
    "\n",
    "    with no_grad():\n",
    "        for input, label in dataloader:\n",
    "            label = label.to(device)\n",
    "            mask = input['attention_mask'].to(device)\n",
    "            input_id = input['input_ids'].squeeze(1).to(device)\n",
    "\n",
    "            output = model(input_id, mask)\n",
    "\n",
    "            total_acc += (output.argmax(dim=1) == label).sum().item()\n",
    "\n",
    "            if criterion:\n",
    "                total_loss += criterion(output, label.long()).item()\n",
    "\n",
    "    if result_type:\n",
    "        print(f\"{result_type.title()} Accuracy: {round(total_acc / len(data), 3)}\")\n",
    "    if criterion:\n",
    "        print(f\"{result_type.title()} Loss: {round(total_loss / len(data), 3)}\")\n",
    "\n",
    "    if criterion:\n",
    "        return total_acc, total_loss\n",
    "    return total_acc\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {
    "id": "3oIVDUu7voS7"
   },
   "outputs": [],
   "source": [
    "def train_model(model, train, val, device, batch_size, learning_rate, epochs):\n",
    "    \"\"\"\n",
    "    Takes in a model, training data, and validation data and trains the given model\n",
    "    Returns None, but changes are saved in the model itself \n",
    "    \"\"\"\n",
    "\n",
    "    #dataloader to iterate through the training dataset\n",
    "    tr_dataloader = DataLoader(train, batch_size=batch_size, shuffle=True)\n",
    "\n",
    "    #loss criterion\n",
    "    criterion = nn.CrossEntropyLoss()\n",
    "\n",
    "    #use GPU if available\n",
    "    if cuda.is_available():\n",
    "        criterion = criterion.cuda()\n",
    "\n",
    "    #optimizer - automatically cuda if model has been switched to cuda\n",
    "    optimizer = Adam(model.parameters(), lr=learning_rate)\n",
    "\n",
    "\n",
    "    for epoch_num in range(epochs):\n",
    "\n",
    "        #model training\n",
    "        total_loss_train = 0\n",
    "        total_acc_train = 0\n",
    "\n",
    "        for train_input, train_label in tqdm(tr_dataloader):\n",
    "            train_label = train_label.to(device)\n",
    "            mask = train_input['attention_mask'].to(device)\n",
    "            input_id = train_input['input_ids'].squeeze(1).to(device)\n",
    "\n",
    "            output = model(input_id, mask)\n",
    "\n",
    "            batch_loss = criterion(output, train_label.long())\n",
    "            total_loss_train += batch_loss.item()\n",
    "\n",
    "            total_acc_train += (output.argmax(dim=1) == train_label).sum().item()\n",
    "\n",
    "            #reset gradients and backwards propagate\n",
    "            model.zero_grad()\n",
    "            batch_loss.backward()\n",
    "            optimizer.step()\n",
    "\n",
    "        #training epoch update\n",
    "        model.update_acc('train', total_acc_train / len(train))\n",
    "        model.update_loss('train', total_loss_train / len(train))\n",
    "\n",
    "        print(f\"Epoch: {epoch_num + 1}\")\n",
    "        print(f\"Train Loss: {round(total_loss_train / len(train), 3)}\")\n",
    "        print(f\"Train Accuracy: {round(total_acc_train / len(train), 3)}\")\n",
    "\n",
    "        #run validation + printed update\n",
    "        total_acc_val, total_loss_val = evaluate(model, val, device, criterion, batch_size, result_type=\"Validation\")\n",
    "        print()\n",
    "\n",
    "        #update val loss/acc in model\n",
    "        model.update_acc('train', total_acc_train / len(train))\n",
    "        model.update_loss('val', total_loss_val / len(val))\n",
    "\n",
    "        #clear cache to hopefully avoid runtime errors\n",
    "        cuda.empty_cache()\n",
    "        gc.collect()\n",
    "    \n",
    "    # total_loss_val = 0\n",
    "    # total_acc_val = 0\n",
    "\n",
    "    # #no back propagation so no need for gradients - much faster\n",
    "    # with no_grad():\n",
    "    #   for val_input, val_label in tqdm(val_dataloader):\n",
    "    #     val_label = val_label.to(Device)\n",
    "    #     mask = val_input['attention_mask'].to(device)\n",
    "    #     input_id = val_input['input_ids'].squeeze(1).to(device)\n",
    "\n",
    "    #     output = model(input_id, mask)\n",
    "\n",
    "    #     batch_loss = criterion(output, val_label.long())\n",
    "    #     total_loss_val += batch_loss.item()\n",
    "\n",
    "    #     acc = (output.argmax(dim=1) == val_label).sum()\n",
    "    #     total_acc_val += acc.item()\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {
    "id": "Wy1QLSBr6CLU"
   },
   "outputs": [],
   "source": [
    "# #create datasets\n",
    "# bert_type = 'bert-base-uncased'\n",
    "# x_col = 'text_combined'\n",
    "# y_col = 'grade_reduced'\n",
    "# labels = {x : i for i, x in enumerate(sorted(train['grade_reduced'].unique(), key=lambda x: int(x.split('.')[1])))}\n",
    "# tokenizer = BertTokenizer.from_pretrained(bert_type)\n",
    "\n",
    "# train_dataset = ClassificationDataset(train, x_col=x_col, y_col=y_col, tokenizer=tokenizer, labels=labels )\n",
    "# val_dataset = ClassificationDataset(val, x_col=x_col, y_col=y_col, tokenizer=tokenizer, labels=labels )\n",
    "# test_dataset = ClassificationDataset(test, x_col=x_col, y_col=y_col, tokenizer=tokenizer, labels=labels )\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {
    "id": "tumQ3_fGaLyh"
   },
   "outputs": [],
   "source": [
    "#create lemmatized datasets\n",
    "bert_type = 'bert-base-uncased'\n",
    "x_col = 'lemmatized_text_combined'\n",
    "y_col = 'grade_reduced'\n",
    "labels = {x : i for i, x in enumerate(sorted(train['grade_reduced'].unique(), key=lambda x: int(x.split('.')[1])))}\n",
    "tokenizer = BertTokenizer.from_pretrained(bert_type)\n",
    "\n",
    "train_lemma_dataset = ClassificationDataset(train, x_col=x_col, y_col=y_col, tokenizer=tokenizer, labels=labels )\n",
    "val_lemma_dataset = ClassificationDataset(val, x_col=x_col, y_col=y_col, tokenizer=tokenizer, labels=labels )\n",
    "test_lemma_dataset = ClassificationDataset(test, x_col=x_col, y_col=y_col, tokenizer=tokenizer, labels=labels )"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/",
     "height": 123,
     "referenced_widgets": [
      "7457be6681844d73a1c09cc4b5227cdd",
      "5dd18e33160743288f2560d9ed7e81d1",
      "0cd289f44d294a6696db7a293324f05d",
      "c6e33b8a8f5146279f587a28ff6a6f03",
      "e6f504852fc443e79d0daffa106e7801",
      "896cb0b12ca542b1a41a93234c7a3ef6",
      "354d02cda9f14fef92bec9dc2c306969",
      "a79735d308514fe4a6f81567c1abcf23",
      "e2447c4a9ca7469a983500e6cd50040a",
      "f3e51437813949c1ac422d4d01fae8de",
      "1a694367b84f4713867e3f15244c296f"
     ]
    },
    "id": "XnulltDHCr1r",
    "outputId": "3678b018-d1c2-48a0-f020-3607fc5967a1"
   },
   "outputs": [
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "7457be6681844d73a1c09cc4b5227cdd",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Downloading pytorch_model.bin:   0%|          | 0.00/420M [00:00<?, ?B/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Some weights of the model checkpoint at bert-base-uncased were not used when initializing BertModel: ['cls.seq_relationship.bias', 'cls.predictions.transform.dense.weight', 'cls.predictions.transform.LayerNorm.weight', 'cls.predictions.transform.dense.bias', 'cls.predictions.decoder.weight', 'cls.predictions.transform.LayerNorm.bias', 'cls.predictions.bias', 'cls.seq_relationship.weight']\n",
      "- This IS expected if you are initializing BertModel from the checkpoint of a model trained on another task or with another architecture (e.g. initializing a BertForSequenceClassification model from a BertForPreTraining model).\n",
      "- This IS NOT expected if you are initializing BertModel from the checkpoint of a model that you expect to be exactly identical (initializing a BertForSequenceClassification model from a BertForSequenceClassification model).\n"
     ]
    }
   ],
   "source": [
    "#create model\n",
    "model = BertClassifier(bert_type=bert_type, num_labels=len(labels), dropout=.5)\n",
    "\n",
    "#use GPU if available\n",
    "if cuda.is_available():\n",
    "    device = dvc(\"cuda\")\n",
    "    model = model.cuda()\n",
    "else:\n",
    "    device = dvc(\"cpu\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "id": "6_7kRHq5WWFJ",
    "outputId": "d58b910e-37ce-4d03-952a-27c003a5eb05"
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "279"
      ]
     },
     "execution_count": 13,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "cuda.empty_cache()\n",
    "gc.collect()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "id": "zjbDkCho75AT",
    "outputId": "87769000-e393-4ec4-e791-4094b264ec40"
   },
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|██████████| 5738/5738 [1:15:44<00:00,  1.26it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch: 1\n",
      "Train Loss: 0.13\n",
      "Train Accuracy: 0.273\n",
      "Validation Accuracy: 0.301\n",
      "Validation Loss: 0.118\n",
      "\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|██████████| 5738/5738 [1:15:48<00:00,  1.26it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch: 2\n",
      "Train Loss: 0.114\n",
      "Train Accuracy: 0.313\n",
      "Validation Accuracy: 0.315\n",
      "Validation Loss: 0.112\n",
      "\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|██████████| 5738/5738 [1:15:46<00:00,  1.26it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch: 3\n",
      "Train Loss: 0.11\n",
      "Train Accuracy: 0.328\n",
      "Validation Accuracy: 0.323\n",
      "Validation Loss: 0.11\n",
      "\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|██████████| 5738/5738 [1:15:45<00:00,  1.26it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch: 4\n",
      "Train Loss: 0.107\n",
      "Train Accuracy: 0.339\n",
      "Validation Accuracy: 0.324\n",
      "Validation Loss: 0.109\n",
      "\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|██████████| 5738/5738 [1:15:46<00:00,  1.26it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch: 5\n",
      "Train Loss: 0.104\n",
      "Train Accuracy: 0.351\n",
      "Validation Accuracy: 0.332\n",
      "Validation Loss: 0.108\n",
      "\n"
     ]
    }
   ],
   "source": [
    "#train model and print progress\n",
    "train_model(model, train_lemma_dataset, val_lemma_dataset, device, batch_size=16, epochs=5, learning_rate=1e-6)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "id": "6Ub9s1Soj74s",
    "outputId": "429e88b8-1ca8-4cf3-bd54-d3da2810132c"
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Test Accuracy: 0.337\n"
     ]
    }
   ],
   "source": [
    "test_acc = evaluate(model, test_lemma_dataset, device, batch_size=2, result_type=\"Test\")\n",
    "model.update_acc('test', test_acc)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/",
     "height": 17
    },
    "id": "RXHrEkdCuw2g",
    "outputId": "2bb58e9e-3bbc-4537-996f-e4aa40d72907"
   },
   "outputs": [
    {
     "data": {
      "application/javascript": [
       "\n",
       "    async function download(id, filename, size) {\n",
       "      if (!google.colab.kernel.accessAllowed) {\n",
       "        return;\n",
       "      }\n",
       "      const div = document.createElement('div');\n",
       "      const label = document.createElement('label');\n",
       "      label.textContent = `Downloading \"${filename}\": `;\n",
       "      div.appendChild(label);\n",
       "      const progress = document.createElement('progress');\n",
       "      progress.max = size;\n",
       "      div.appendChild(progress);\n",
       "      document.body.appendChild(div);\n",
       "\n",
       "      const buffers = [];\n",
       "      let downloaded = 0;\n",
       "\n",
       "      const channel = await google.colab.kernel.comms.open(id);\n",
       "      // Send a message to notify the kernel that we're ready.\n",
       "      channel.send({})\n",
       "\n",
       "      for await (const message of channel.messages) {\n",
       "        // Send a message to notify the kernel that we're ready.\n",
       "        channel.send({})\n",
       "        if (message.buffers) {\n",
       "          for (const buffer of message.buffers) {\n",
       "            buffers.push(buffer);\n",
       "            downloaded += buffer.byteLength;\n",
       "            progress.value = downloaded;\n",
       "          }\n",
       "        }\n",
       "      }\n",
       "      const blob = new Blob(buffers, {type: 'application/binary'});\n",
       "      const a = document.createElement('a');\n",
       "      a.href = window.URL.createObjectURL(blob);\n",
       "      a.download = filename;\n",
       "      div.appendChild(a);\n",
       "      a.click();\n",
       "      div.remove();\n",
       "    }\n",
       "  "
      ],
      "text/plain": [
       "<IPython.core.display.Javascript object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "application/javascript": [
       "download(\"download_969e06e7-04f4-4369-a2fb-b84d37b49526\", \"model.pt\", 438086443)"
      ],
      "text/plain": [
       "<IPython.core.display.Javascript object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "#https://www.honchosearch.com/blog/seo/how-to-download-files-from-google-colab/#:~:text=To%20download%20a%20file%20for,then%20this%20won't%20work.&text=Once%20executed%2C%20this%20will%20download%20the%20file%20directly%20to%20your%20downloads.\n",
    "save(model, 'model.pt')\n",
    "files.download('model.pt')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "lG3hHLp46lvY"
   },
   "outputs": [],
   "source": [
    "\n"
   ]
  }
 ],
 "metadata": {
  "accelerator": "GPU",
  "colab": {
   "background_execution": "on",
   "collapsed_sections": [],
   "name": "BertBaseUncased (1).ipynb",
   "provenance": []
  },
  "gpuClass": "standard",
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.9.7"
  },
  "widgets": {
   "application/vnd.jupyter.widget-state+json": {
    "0cd289f44d294a6696db7a293324f05d": {
     "model_module": "@jupyter-widgets/controls",
     "model_module_version": "1.5.0",
     "model_name": "FloatProgressModel",
     "state": {
      "_dom_classes": [],
      "_model_module": "@jupyter-widgets/controls",
      "_model_module_version": "1.5.0",
      "_model_name": "FloatProgressModel",
      "_view_count": null,
      "_view_module": "@jupyter-widgets/controls",
      "_view_module_version": "1.5.0",
      "_view_name": "ProgressView",
      "bar_style": "success",
      "description": "",
      "description_tooltip": null,
      "layout": "IPY_MODEL_a79735d308514fe4a6f81567c1abcf23",
      "max": 440473133,
      "min": 0,
      "orientation": "horizontal",
      "style": "IPY_MODEL_e2447c4a9ca7469a983500e6cd50040a",
      "value": 440473133
     }
    },
    "1a694367b84f4713867e3f15244c296f": {
     "model_module": "@jupyter-widgets/controls",
     "model_module_version": "1.5.0",
     "model_name": "DescriptionStyleModel",
     "state": {
      "_model_module": "@jupyter-widgets/controls",
      "_model_module_version": "1.5.0",
      "_model_name": "DescriptionStyleModel",
      "_view_count": null,
      "_view_module": "@jupyter-widgets/base",
      "_view_module_version": "1.2.0",
      "_view_name": "StyleView",
      "description_width": ""
     }
    },
    "354d02cda9f14fef92bec9dc2c306969": {
     "model_module": "@jupyter-widgets/controls",
     "model_module_version": "1.5.0",
     "model_name": "DescriptionStyleModel",
     "state": {
      "_model_module": "@jupyter-widgets/controls",
      "_model_module_version": "1.5.0",
      "_model_name": "DescriptionStyleModel",
      "_view_count": null,
      "_view_module": "@jupyter-widgets/base",
      "_view_module_version": "1.2.0",
      "_view_name": "StyleView",
      "description_width": ""
     }
    },
    "5dd18e33160743288f2560d9ed7e81d1": {
     "model_module": "@jupyter-widgets/controls",
     "model_module_version": "1.5.0",
     "model_name": "HTMLModel",
     "state": {
      "_dom_classes": [],
      "_model_module": "@jupyter-widgets/controls",
      "_model_module_version": "1.5.0",
      "_model_name": "HTMLModel",
      "_view_count": null,
      "_view_module": "@jupyter-widgets/controls",
      "_view_module_version": "1.5.0",
      "_view_name": "HTMLView",
      "description": "",
      "description_tooltip": null,
      "layout": "IPY_MODEL_896cb0b12ca542b1a41a93234c7a3ef6",
      "placeholder": "​",
      "style": "IPY_MODEL_354d02cda9f14fef92bec9dc2c306969",
      "value": "Downloading pytorch_model.bin: 100%"
     }
    },
    "7457be6681844d73a1c09cc4b5227cdd": {
     "model_module": "@jupyter-widgets/controls",
     "model_module_version": "1.5.0",
     "model_name": "HBoxModel",
     "state": {
      "_dom_classes": [],
      "_model_module": "@jupyter-widgets/controls",
      "_model_module_version": "1.5.0",
      "_model_name": "HBoxModel",
      "_view_count": null,
      "_view_module": "@jupyter-widgets/controls",
      "_view_module_version": "1.5.0",
      "_view_name": "HBoxView",
      "box_style": "",
      "children": [
       "IPY_MODEL_5dd18e33160743288f2560d9ed7e81d1",
       "IPY_MODEL_0cd289f44d294a6696db7a293324f05d",
       "IPY_MODEL_c6e33b8a8f5146279f587a28ff6a6f03"
      ],
      "layout": "IPY_MODEL_e6f504852fc443e79d0daffa106e7801"
     }
    },
    "896cb0b12ca542b1a41a93234c7a3ef6": {
     "model_module": "@jupyter-widgets/base",
     "model_module_version": "1.2.0",
     "model_name": "LayoutModel",
     "state": {
      "_model_module": "@jupyter-widgets/base",
      "_model_module_version": "1.2.0",
      "_model_name": "LayoutModel",
      "_view_count": null,
      "_view_module": "@jupyter-widgets/base",
      "_view_module_version": "1.2.0",
      "_view_name": "LayoutView",
      "align_content": null,
      "align_items": null,
      "align_self": null,
      "border": null,
      "bottom": null,
      "display": null,
      "flex": null,
      "flex_flow": null,
      "grid_area": null,
      "grid_auto_columns": null,
      "grid_auto_flow": null,
      "grid_auto_rows": null,
      "grid_column": null,
      "grid_gap": null,
      "grid_row": null,
      "grid_template_areas": null,
      "grid_template_columns": null,
      "grid_template_rows": null,
      "height": null,
      "justify_content": null,
      "justify_items": null,
      "left": null,
      "margin": null,
      "max_height": null,
      "max_width": null,
      "min_height": null,
      "min_width": null,
      "object_fit": null,
      "object_position": null,
      "order": null,
      "overflow": null,
      "overflow_x": null,
      "overflow_y": null,
      "padding": null,
      "right": null,
      "top": null,
      "visibility": null,
      "width": null
     }
    },
    "a79735d308514fe4a6f81567c1abcf23": {
     "model_module": "@jupyter-widgets/base",
     "model_module_version": "1.2.0",
     "model_name": "LayoutModel",
     "state": {
      "_model_module": "@jupyter-widgets/base",
      "_model_module_version": "1.2.0",
      "_model_name": "LayoutModel",
      "_view_count": null,
      "_view_module": "@jupyter-widgets/base",
      "_view_module_version": "1.2.0",
      "_view_name": "LayoutView",
      "align_content": null,
      "align_items": null,
      "align_self": null,
      "border": null,
      "bottom": null,
      "display": null,
      "flex": null,
      "flex_flow": null,
      "grid_area": null,
      "grid_auto_columns": null,
      "grid_auto_flow": null,
      "grid_auto_rows": null,
      "grid_column": null,
      "grid_gap": null,
      "grid_row": null,
      "grid_template_areas": null,
      "grid_template_columns": null,
      "grid_template_rows": null,
      "height": null,
      "justify_content": null,
      "justify_items": null,
      "left": null,
      "margin": null,
      "max_height": null,
      "max_width": null,
      "min_height": null,
      "min_width": null,
      "object_fit": null,
      "object_position": null,
      "order": null,
      "overflow": null,
      "overflow_x": null,
      "overflow_y": null,
      "padding": null,
      "right": null,
      "top": null,
      "visibility": null,
      "width": null
     }
    },
    "c6e33b8a8f5146279f587a28ff6a6f03": {
     "model_module": "@jupyter-widgets/controls",
     "model_module_version": "1.5.0",
     "model_name": "HTMLModel",
     "state": {
      "_dom_classes": [],
      "_model_module": "@jupyter-widgets/controls",
      "_model_module_version": "1.5.0",
      "_model_name": "HTMLModel",
      "_view_count": null,
      "_view_module": "@jupyter-widgets/controls",
      "_view_module_version": "1.5.0",
      "_view_name": "HTMLView",
      "description": "",
      "description_tooltip": null,
      "layout": "IPY_MODEL_f3e51437813949c1ac422d4d01fae8de",
      "placeholder": "​",
      "style": "IPY_MODEL_1a694367b84f4713867e3f15244c296f",
      "value": " 420M/420M [00:08&lt;00:00, 49.8MB/s]"
     }
    },
    "e2447c4a9ca7469a983500e6cd50040a": {
     "model_module": "@jupyter-widgets/controls",
     "model_module_version": "1.5.0",
     "model_name": "ProgressStyleModel",
     "state": {
      "_model_module": "@jupyter-widgets/controls",
      "_model_module_version": "1.5.0",
      "_model_name": "ProgressStyleModel",
      "_view_count": null,
      "_view_module": "@jupyter-widgets/base",
      "_view_module_version": "1.2.0",
      "_view_name": "StyleView",
      "bar_color": null,
      "description_width": ""
     }
    },
    "e6f504852fc443e79d0daffa106e7801": {
     "model_module": "@jupyter-widgets/base",
     "model_module_version": "1.2.0",
     "model_name": "LayoutModel",
     "state": {
      "_model_module": "@jupyter-widgets/base",
      "_model_module_version": "1.2.0",
      "_model_name": "LayoutModel",
      "_view_count": null,
      "_view_module": "@jupyter-widgets/base",
      "_view_module_version": "1.2.0",
      "_view_name": "LayoutView",
      "align_content": null,
      "align_items": null,
      "align_self": null,
      "border": null,
      "bottom": null,
      "display": null,
      "flex": null,
      "flex_flow": null,
      "grid_area": null,
      "grid_auto_columns": null,
      "grid_auto_flow": null,
      "grid_auto_rows": null,
      "grid_column": null,
      "grid_gap": null,
      "grid_row": null,
      "grid_template_areas": null,
      "grid_template_columns": null,
      "grid_template_rows": null,
      "height": null,
      "justify_content": null,
      "justify_items": null,
      "left": null,
      "margin": null,
      "max_height": null,
      "max_width": null,
      "min_height": null,
      "min_width": null,
      "object_fit": null,
      "object_position": null,
      "order": null,
      "overflow": null,
      "overflow_x": null,
      "overflow_y": null,
      "padding": null,
      "right": null,
      "top": null,
      "visibility": null,
      "width": null
     }
    },
    "f3e51437813949c1ac422d4d01fae8de": {
     "model_module": "@jupyter-widgets/base",
     "model_module_version": "1.2.0",
     "model_name": "LayoutModel",
     "state": {
      "_model_module": "@jupyter-widgets/base",
      "_model_module_version": "1.2.0",
      "_model_name": "LayoutModel",
      "_view_count": null,
      "_view_module": "@jupyter-widgets/base",
      "_view_module_version": "1.2.0",
      "_view_name": "LayoutView",
      "align_content": null,
      "align_items": null,
      "align_self": null,
      "border": null,
      "bottom": null,
      "display": null,
      "flex": null,
      "flex_flow": null,
      "grid_area": null,
      "grid_auto_columns": null,
      "grid_auto_flow": null,
      "grid_auto_rows": null,
      "grid_column": null,
      "grid_gap": null,
      "grid_row": null,
      "grid_template_areas": null,
      "grid_template_columns": null,
      "grid_template_rows": null,
      "height": null,
      "justify_content": null,
      "justify_items": null,
      "left": null,
      "margin": null,
      "max_height": null,
      "max_width": null,
      "min_height": null,
      "min_width": null,
      "object_fit": null,
      "object_position": null,
      "order": null,
      "overflow": null,
      "overflow_x": null,
      "overflow_y": null,
      "padding": null,
      "right": null,
      "top": null,
      "visibility": null,
      "width": null
     }
    }
   }
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
